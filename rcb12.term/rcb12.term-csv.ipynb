{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37764bit54b629de4ec7432ea8f490cfc7e2cda2",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: Octo-Tiger HPX output, including Performance counter values\n",
    "\n",
    "Output: CSV\n",
    "```csv\n",
    "iteration,locality,subgrids,amr_bound,subgrid_leaves,idle_rate_0,idle_rate_1,...,idle_rate_19\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lzma\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pfx_counter_line_pattern():\n",
    "    return re.compile(\n",
    "        r'^/[^{]+\\{[^}]+\\}/([^,]+,){4,5}[^,\\n]+$', re.MULTILINE)\n",
    "\n",
    "\n",
    "def test_pfx_counter_line_pattern(pattern):\n",
    "    def test_case(subject):\n",
    "        return [i.group() for i in pattern.finditer(subject)]\n",
    "\n",
    "    subject = '''\n",
    "/octotiger{locality#0/total}/subgrid_leaves,2,3602.438779,[s],32428\n",
    "/octotiger{locality#1/total}/subgrid_leaves,2,3602.428582,[s],34118\n",
    "/octotiger{locality#2/total}/subgrid_leaves,2,3602.430246,[s],33918\n",
    "/octotiger{locality#3/total}/subgrid_leaves,2,3602.431576,[s],34443\n",
    "/octotiger{locality#4/total}/subgrid_leaves,2,3602.436175,[s],33173\n",
    "/threads{locality#59/total/total}/count/cumulative,44,154828.198473,[s],2.3065e+09\n",
    "/threads{locality#60/total/total}/count/cumulative,44,154828.221342,[s],2.24724e+09\n",
    "/threads{locality#61/total/total}/count/cumulative,44,154828.184221,[s],2.28135e+09\n",
    "/threads{locality#62/total/total}/count/cumulative,44,154828.221351,[s],2.20491e+09\n",
    "/threads{locality#63/total/total}/count/cumulative,44,154828.216028,[s],2.05324e+09\n",
    "/threads{locality#0/pool#default/worker-thread#0}/count/cumulative,44,154828.257432,[s],1.14378e+08\n",
    "/threads{locality#0/pool#default/worker-thread#1}/count/cumulative,44,154828.260203,[s],1.05219e+08\n",
    "/threads{locality#0/pool#default/worker-thread#2}/count/cumulative,44,154828.262954,[s],1.04616e+08\n",
    "/threads{locality#0/pool#default/worker-thread#3}/count/cumulative,44,154828.262962,[s],1.04786e+08\n",
    "    '''\n",
    "    expected = [\n",
    "        '/octotiger{locality#0/total}/subgrid_leaves,2,3602.438779,[s],32428',\n",
    "        '/octotiger{locality#1/total}/subgrid_leaves,2,3602.428582,[s],34118',\n",
    "        '/octotiger{locality#2/total}/subgrid_leaves,2,3602.430246,[s],33918',\n",
    "        '/octotiger{locality#3/total}/subgrid_leaves,2,3602.431576,[s],34443',\n",
    "        '/octotiger{locality#4/total}/subgrid_leaves,2,3602.436175,[s],33173',\n",
    "        '/threads{locality#59/total/total}/count/cumulative,44,154828.198473,[s],2.3065e+09',\n",
    "        '/threads{locality#60/total/total}/count/cumulative,44,154828.221342,[s],2.24724e+09',\n",
    "        '/threads{locality#61/total/total}/count/cumulative,44,154828.184221,[s],2.28135e+09',\n",
    "        '/threads{locality#62/total/total}/count/cumulative,44,154828.221351,[s],2.20491e+09',\n",
    "        '/threads{locality#63/total/total}/count/cumulative,44,154828.216028,[s],2.05324e+09',\n",
    "        '/threads{locality#0/pool#default/worker-thread#0}/count/cumulative,44,154828.257432,[s],1.14378e+08',\n",
    "        '/threads{locality#0/pool#default/worker-thread#1}/count/cumulative,44,154828.260203,[s],1.05219e+08',\n",
    "        '/threads{locality#0/pool#default/worker-thread#2}/count/cumulative,44,154828.262954,[s],1.04616e+08',\n",
    "        '/threads{locality#0/pool#default/worker-thread#3}/count/cumulative,44,154828.262962,[s],1.04786e+08'\n",
    "    ]\n",
    "\n",
    "    assert test_case(subject) == expected\n",
    "\n",
    "# Counter line search and counter name parsing regex patterns\n",
    "pfx_counter_line_pattern = get_pfx_counter_line_pattern()\n",
    "test_pfx_counter_line_pattern(pfx_counter_line_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_general_counter_form_pattern():\n",
    "    return re.compile(\n",
    "        r'/(?P<object>[^{]+)\\{locality#(?P<locality>\\d+)/(?:(?:(?P<instance1>pool#[^/]+/[^#]+)#(?P<thread_id>\\d+))|(?P<instance2>[^}]+))\\}/(?P<counter>[^@]+)(?:@(?P<params>.+))?')\n",
    "\n",
    "\n",
    "def test_general_counter_form_pattern(pattern):\n",
    "    def run_test_case(subject):\n",
    "        m = pattern.match(subject)\n",
    "        assert m is not None\n",
    "        return m.groupdict()\n",
    "\n",
    "    assert run_test_case('/threads{locality#0/pool#default/worker-thread#0}/count/cumulative') == {\n",
    "        'object': 'threads',\n",
    "        'locality': '0',\n",
    "        'instance1': 'pool#default/worker-thread',\n",
    "        'thread_id': '0',\n",
    "        'instance2': None,\n",
    "        'counter': 'count/cumulative',\n",
    "        'params': None}\n",
    "    assert run_test_case('/threads{locality#61/total/total}/count/cumulative,44,154828.184221,[s],2.28135e+09') == {\n",
    "        'object': 'threads',\n",
    "        'locality': '61',\n",
    "        'instance1': None,\n",
    "        'thread_id': None,\n",
    "        'instance2': 'total/total',\n",
    "        'counter': 'count/cumulative,44,154828.184221,[s],2.28135e+09',\n",
    "        'params': None}\n",
    "\n",
    "general_counter_form_pattern = get_general_counter_form_pattern()\n",
    "test_general_counter_form_pattern(general_counter_form_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpx_output_files = glob.glob('*.txt.xz')\n",
    "assert isinstance(hpx_output_files, list)\n",
    "assert len(hpx_output_files) >= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    assert os.access(filepath, os.R_OK)\n",
    "\n",
    "    # Read one file for testing\n",
    "    with lzma.open(filepath, 'rt', encoding='utf-8') as hpx_output_handle:\n",
    "        hpx_output = hpx_output_handle.read()\n",
    "    return hpx_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Read one file for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "subject: ./64_4.txt.xz\n"
    }
   ],
   "source": [
    "r0f = os.path.join(os.curdir, hpx_output_files[0])\n",
    "print('subject:', r0f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpx_output = read_file(r0f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_counters_df(hpx_output):\n",
    "    assert isinstance(hpx_output, str)\n",
    "\n",
    "    all_counters = []\n",
    "    for pfx_counter_line in pfx_counter_line_pattern.finditer(hpx_output):\n",
    "        raw_line = pfx_counter_line.group(0)\n",
    "        line_split = raw_line.split(',')\n",
    "\n",
    "        def justify_fields(line_split):\n",
    "            if len(line_split) == 5:\n",
    "                # Unit for count values\n",
    "                line_split += ('1')\n",
    "            assert len(line_split) == 6\n",
    "        justify_fields(line_split)\n",
    "\n",
    "        raw_general_name = line_split[0]\n",
    "        split_general_form = general_counter_form_pattern.match(\n",
    "            raw_general_name)\n",
    "        assert split_general_form is not None\n",
    "\n",
    "        countername_groups = split_general_form.groupdict()\n",
    "\n",
    "        def unify_instance_field(countername_groups):\n",
    "            if countername_groups['instance1'] is not None:\n",
    "                countername_groups['instance'] = countername_groups['instance1']\n",
    "            else:\n",
    "                countername_groups['instance'] = countername_groups['instance2']\n",
    "\n",
    "            del countername_groups['instance1']\n",
    "            del countername_groups['instance2']\n",
    "        unify_instance_field(countername_groups)\n",
    "\n",
    "        all_counters += [(\n",
    "            countername_groups[\"object\"],\n",
    "            countername_groups[\"locality\"],\n",
    "            countername_groups[\"instance\"],\n",
    "            countername_groups[\"counter\"],\n",
    "            countername_groups[\"thread_id\"],\n",
    "            countername_groups[\"params\"],\n",
    "        ) + tuple(line_split)]\n",
    "\n",
    "    df = pd.DataFrame(all_counters, columns=[\n",
    "        'objectname', 'locality', 'instance', 'countername', 'thread_id',\n",
    "        'parameters', 'general_form', 'iteration', 'timestamp',\n",
    "        'timestamp_unit', 'value', 'unit'])\n",
    "    assert isinstance(df, pd.DataFrame)\n",
    "    assert len(df) != 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 2.75 s, sys: 139 ms, total: 2.88 s\nWall time: 2.9 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "df = extract_counters_df(hpx_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_prune_fields(df):\n",
    "    assert isinstance(df, pd.DataFrame)\n",
    "\n",
    "    def fix_units(df):\n",
    "        df.locality = pd.to_numeric(df.locality, downcast='unsigned')\n",
    "        df.iteration = pd.to_numeric(df.iteration, downcast='unsigned')\n",
    "        df.timestamp = pd.to_numeric(df.timestamp)\n",
    "        df.value = pd.to_numeric(df.value)\n",
    "        df.thread_id = pd.to_numeric(df.thread_id, downcast='unsigned')\n",
    "        df.loc[df.countername == 'idle-rate', 'value'] *= 0.01\n",
    "    fix_units(df)\n",
    "\n",
    "    def drop_irrelevant_counters(df):\n",
    "        # Drop AGAS results\n",
    "        df.drop(df.index[df.objectname == 'agas'], inplace=True)\n",
    "        # Drop threads...pool#default/worker-thread...count/cumulative-phases\n",
    "        df.drop(df.index[df.countername == 'count/cumulative-phases'], inplace=True)\n",
    "        df.drop(df.index[df.countername == 'count/cumulative'], inplace=True)\n",
    "\n",
    "    drop_irrelevant_counters(df)\n",
    "\n",
    "    # Units can only be [0.01%], 1, [s], and [ns]\n",
    "    def check_all_data_units(df):\n",
    "        x = df.loc[(df.unit != '1')]\n",
    "        x = x.loc[x.unit != '[0.01%]']\n",
    "        x = x.loc[x.unit != '[s]']\n",
    "        x = x.loc[x.unit != '[ns]']\n",
    "        assert len(x) == 0\n",
    "\n",
    "    check_all_data_units(df)\n",
    "\n",
    "    def remove_unused_columns(df):\n",
    "        # No parameters are expected\n",
    "        assert len(df.loc[~df.parameters.isnull()]) == 0\n",
    "        del df['parameters']\n",
    "\n",
    "        del df['timestamp_unit']\n",
    "        del df['unit']\n",
    "        del df['timestamp']\n",
    "        del df['general_form']\n",
    "    remove_unused_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_and_prune_fields(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df):\n",
    "    def get_octotiger_counters(df):\n",
    "        octo_pivot = df.pivot_table(\n",
    "            index=[\n",
    "                'iteration',\n",
    "                'locality'],\n",
    "            columns=['countername'],\n",
    "            values='value',\n",
    "            dropna=False)\n",
    "        del octo_pivot['idle-rate']\n",
    "        return octo_pivot\n",
    "    octotiger_counters = get_octotiger_counters(df)\n",
    "\n",
    "    def get_idle_rate_counters(df):\n",
    "        idle_rate_pivot = df.pivot_table(\n",
    "            index=[\n",
    "                'iteration',\n",
    "                'locality'],\n",
    "            columns=['thread_id'],\n",
    "            values='value')\n",
    "        return idle_rate_pivot\n",
    "    idle_rates = get_idle_rate_counters(df)\n",
    "\n",
    "    result = pd.concat([octotiger_counters, idle_rates], axis=1)\n",
    "    result.reset_index(inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_output_path(original_path):\n",
    "    return os.path.splitext(original_path)[0] + '.csv'\n",
    "of = get_csv_output_path(r0f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  }
 ]
}